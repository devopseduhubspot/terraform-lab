
# üì¶ Kubernetes Application Deployment
# This file tells Kubernetes exactly how to run your web application

# Application Deployment Configuration
apiVersion: apps/v1      # Kubernetes API version
kind: Deployment         # Type: Application deployment
metadata:
  name: demo-app         # Name of your application

spec:
  replicas: 2            # Run 2 copies of the app (for reliability)
  selector:              # How to find the app instances
    matchLabels:
      app: demo          # Look for pods labeled "demo"
      
  template:              # Blueprint for each app instance
    metadata:
      labels:
        app: demo        # Label each instance as "demo"
    spec:
      containers:        # The actual application container
      - name: demo-container
        image: nginx     # Use Nginx web server (popular, reliable)
        ports:
        - containerPort: 80  # App listens on port 80 (standard web port)

---  # Separator between different Kubernetes resources

# Load Balancer Service Configuration  
apiVersion: v1           # Kubernetes API version
kind: Service            # Type: Network service
metadata:
  name: demo-service     # Name of the load balancer

spec:
  type: LoadBalancer     # Create AWS Load Balancer (gets public IP)
  selector:
    app: demo            # Send traffic to pods labeled "demo"
  ports:
    - port: 80           # Load balancer receives traffic on port 80
      targetPort: 80     # Forward traffic to container port 80

# üéì What This Does:
# 1. Creates 2 copies of Nginx web server
# 2. If one crashes, Kubernetes restarts it automatically  
# 3. Creates AWS Load Balancer with public IP
# 4. Load balancer distributes traffic between the 2 app copies
# 5. Users access your app via the load balancer's public IP

# üåê Real-World Analogy:
# Deployment = Instructions for hiring 2 identical workers
# Containers = The actual workers (Nginx web servers)
# Service = Reception desk that directs visitors to available workers
# LoadBalancer = Public address for your business

# üí° Why 2 Replicas:
# - High availability: If 1 server fails, 1 continues serving users
# - Load distribution: 2 servers can handle more traffic than 1
# - Zero downtime: Can update 1 server while other serves traffic

# üè¢ Production Examples:
# - Netflix: Runs thousands of replicas across multiple regions
# - Amazon: Uses similar setup for shopping website
# - Google: Search runs on thousands of replicas worldwide

# üöÄ Scaling Example:
# To handle more traffic, change "replicas: 2" to "replicas: 10"
# Kubernetes automatically creates 8 more app instances!
